# Toxic_comment_classification
To build a multi-headed model thatâ€™s capable of detecting different types of toxicity like threats, obscenity, insults, and identity-based hate.
This is a multi-label classification problem. 
It differs from multi-class classification problem in which each sample can only be assigned to one of the many labels
. But in this problem each comment can belong to more than one label for e.g., a comment can be obscene, toxic and insult, all at the same time.
